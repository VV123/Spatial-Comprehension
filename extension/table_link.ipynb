{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "table_link.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d05500e0130046dbbe6feec01cc90e82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_46e68125f05e46e6a5858862b792f7fe",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_7a1519be01e243489a4fc653286b2c2f",
              "IPY_MODEL_4603da02e25442eab88908d4bdf3e393"
            ]
          }
        },
        "46e68125f05e46e6a5858862b792f7fe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7a1519be01e243489a4fc653286b2c2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_027ffb7c707e4464b5d0466cdb9d5f28",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_033ebe4d04c74c84b263ff05358f74a7"
          }
        },
        "4603da02e25442eab88908d4bdf3e393": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9efd6fe1c5014322a3a95bdad7318d75",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 670kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e68fde583a374186b942be767bd45248"
          }
        },
        "027ffb7c707e4464b5d0466cdb9d5f28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "033ebe4d04c74c84b263ff05358f74a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9efd6fe1c5014322a3a95bdad7318d75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e68fde583a374186b942be767bd45248": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0e9ccd7df1c346f18c08d693c020201a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_1dd4bd60c2a14a48a8874fd6e1ff0198",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_afa77d82ab9c4470ac6cb91ff450ae13",
              "IPY_MODEL_19f87b9c354e48bfa9c1aa1821515401"
            ]
          }
        },
        "1dd4bd60c2a14a48a8874fd6e1ff0198": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "afa77d82ab9c4470ac6cb91ff450ae13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_39701143bf1e436f92ccd57b8efac354",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 433,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 433,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d707fd4a3b414c30a629b6cdc0285765"
          }
        },
        "19f87b9c354e48bfa9c1aa1821515401": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9a8c58ebba4947ccb7ab53920bcde607",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 433/433 [00:12&lt;00:00, 33.8B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1359b51272df477995c20c8724810861"
          }
        },
        "39701143bf1e436f92ccd57b8efac354": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d707fd4a3b414c30a629b6cdc0285765": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9a8c58ebba4947ccb7ab53920bcde607": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1359b51272df477995c20c8724810861": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0254095923c647d8986487d78b625d1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_444dbba966d14c95977dc9980181dddb",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f4a603b606514cbcaa4af43f08e02682",
              "IPY_MODEL_e4021fcf00ce49148b663644b96b955a"
            ]
          }
        },
        "444dbba966d14c95977dc9980181dddb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f4a603b606514cbcaa4af43f08e02682": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_248a52af67a14c01b1900202fc1815a4",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_708f47eda91246d9ae51b75959256a8c"
          }
        },
        "e4021fcf00ce49148b663644b96b955a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7116a63b67714e3dbac50646fd72a4ee",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 440M/440M [00:12&lt;00:00, 36.5MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2df467bc3fba41b98baa5a5a2e48ac23"
          }
        },
        "248a52af67a14c01b1900202fc1815a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "708f47eda91246d9ae51b75959256a8c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7116a63b67714e3dbac50646fd72a4ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2df467bc3fba41b98baa5a5a2e48ac23": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "NNP2W7yfkAoB"
      },
      "source": [
        "!pip install --upgrade transformers\n",
        "!pip install simpletransformers\n",
        "# memory footprint support libraries/code\n",
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install humanize importing libraries"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I1iXthLuGbop",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "705c1aca-52e0-45fb-bab8-1a6ad020a4c6"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_5uczpx-kcCN"
      },
      "source": [
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from google.colab import files\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "warnings.simplefilter('ignore')\n",
        "import gc\n",
        "from scipy.special import softmax\n",
        "from simpletransformers.classification import ClassificationModel\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, KFold \n",
        "import sklearn\n",
        "from sklearn.metrics import log_loss\n",
        "from sklearn.metrics import *\n",
        "from sklearn.model_selection import *\n",
        "import re\n",
        "import random\n",
        "import torch\n",
        "pd.options.display.max_colwidth = 200\n",
        "\n",
        "#choose the same seed to assure that our model will be roproducible\n",
        "\n",
        "def seed_all(seed_value):\n",
        "    random.seed(seed_value) # Python\n",
        "    np.random.seed(seed_value) # cpu vars\n",
        "    torch.manual_seed(seed_value) # cpu  vars\n",
        "    \n",
        "    if torch.cuda.is_available(): \n",
        "        torch.cuda.manual_seed(seed_value)\n",
        "        torch.cuda.manual_seed_all(seed_value) # gpu vars\n",
        "        torch.backends.cudnn.deterministic = True  #needed\n",
        "        torch.backends.cudnn.benchmark = False\n",
        "\n",
        "seed_all(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4H4bwDXNkgo0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb4c0e05-c32b-44de-b2ed-03dc575ecab6"
      },
      "source": [
        "cd '/content/drive/My Drive/sql-jing1'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/sql-jing1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lV4rhGJmktYu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 100,
          "referenced_widgets": [
            "d05500e0130046dbbe6feec01cc90e82",
            "46e68125f05e46e6a5858862b792f7fe",
            "7a1519be01e243489a4fc653286b2c2f",
            "4603da02e25442eab88908d4bdf3e393",
            "027ffb7c707e4464b5d0466cdb9d5f28",
            "033ebe4d04c74c84b263ff05358f74a7",
            "9efd6fe1c5014322a3a95bdad7318d75",
            "e68fde583a374186b942be767bd45248"
          ]
        },
        "outputId": "b862c628-f574-4743-cd34-f3048067ddd5"
      },
      "source": [
        "import random\n",
        "from transformers import BertTokenizer, BertModel\n",
        "Y = ['mountain', 'border', 'high', 'city', 'state', 'river']\n",
        "def read_file(data='train',batch_size=16,max_len=22):\n",
        "\n",
        "  filename = data + '_org.qu'\n",
        "  x, xt, y = [], [], []\n",
        "  sent_x, sent_t = [], []\n",
        "\n",
        "  with open(filename) as f:\n",
        "    ls = f.readlines()\n",
        "  total = len(ls)\n",
        "  num_batch = int((total+batch_size)/batch_size)\n",
        "  for i in range(num_batch):\n",
        "    st = batch_size * i\n",
        "    ed = min(batch_size * i + batch_size, total)\n",
        "    x_batch, xt_batch, y_batch = [], [], []\n",
        "    sent_x_batch, sent_t_batch = [], []\n",
        "    for j in range(st, ed):\n",
        "      l = ls[j]\n",
        "      tables = l.strip('\\n').split('\\t')[0].split()\n",
        "      tables = [t.replace('table_','').replace('_info','') for t in tables]\n",
        "      \n",
        "      question = l.strip('\\n').split('\\t')[1]\n",
        "      tokenized_input = tokenizer.tokenize(question) \n",
        "      while len(tokenized_input) < max_len:\n",
        "          tokenized_input.append('[PAD]')\n",
        "      x_idx = tokenizer.convert_tokens_to_ids(tokenized_input)\n",
        "      #positive samples\n",
        "      for t in tables:\n",
        "        sent_x_batch.append(question)\n",
        "        #print(x_idx)\n",
        "        x_batch.append(x_idx)\n",
        "\n",
        "        sent_t_batch.append(t)\n",
        "        xt_idx = tokenizer.convert_tokens_to_ids([t])\n",
        "        xt_batch.append(xt_idx)\n",
        "        y_batch.append(1.0)\n",
        "\n",
        "      #negative sampling\n",
        "      YY = [t for t in Y if t not in tables]\n",
        "      for t in YY:\n",
        "        sent_x_batch.append(question)\n",
        "        sent_t_batch.append(t)\n",
        "        xt_idx = tokenizer.convert_tokens_to_ids([t])\n",
        "        x_batch.append(x_idx)\n",
        "        xt_batch.append(xt_idx)\n",
        "        y_batch.append(0.0)\n",
        "\n",
        "      #positive sampling for balance\n",
        "      if data == '.':\n",
        "        for j in range(len(YY)-len(tables)):\n",
        "          t = random.choice(tables)\n",
        "          sent_x_batch.append(question)\n",
        "          sent_t_batch.append(t)\n",
        "          x_batch.append(x_idx)\n",
        "          xt_idx = tokenizer.convert_tokens_to_ids([t])\n",
        "          xt_batch.append(xt_idx)\n",
        "          y_batch.append(1.0)\n",
        "\n",
        "    x_batch = np.asarray(x_batch)\n",
        "    #print(x_batch.shape)\n",
        "    x_batch = np.transpose(x_batch, (1,0))\n",
        "    xt_batch = np.asarray(xt_batch)\n",
        "    xt_batch = np.transpose(xt_batch, (1,0))\n",
        "    y_batch = np.asarray(y_batch)\n",
        "    sent_x_batch = np.asarray(sent_x_batch)\n",
        "    sent_t_batch = np.asarray(sent_t_batch)\n",
        "\n",
        "    x.append(torch.tensor(x_batch, dtype=torch.long, device=device))\n",
        "    xt.append(torch.tensor(xt_batch, dtype=torch.long, device=device))\n",
        "    y.append(torch.tensor(y_batch, dtype=torch.float, device=device))\n",
        "    sent_x.append(sent_x_batch)\n",
        "    sent_t.append(sent_t_batch)\n",
        "  print(total)\n",
        "  return x, xt, y, sent_x, sent_t\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "train_x, train_xt, train_y, _, _ = read_file('train')\n",
        "assert len(train_x) == len(train_xt) == len(train_y)\n",
        "test_x, test_xt, test_y, sent_x, sent_t = read_file('test')\n",
        "assert len(test_x) == len(test_xt) == len(test_y) == len(sent_x) == len(sent_t)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d05500e0130046dbbe6feec01cc90e82",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descriptiâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "1647\n",
            "279\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4zMZ6mecF0M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e0020b3-15e9-42b4-a3ce-c9d72e79adce"
      },
      "source": [
        "pos, ttl = 0, 0\n",
        "for l in train_y:\n",
        "  ttl += l.size(0)\n",
        "  pos += sum(l)\n",
        "print('train positive {0} total {1}'.format(pos, ttl))\n",
        "pos, ttl = 0, 0\n",
        "for l in test_y:\n",
        "  ttl += l.size(0)\n",
        "  pos += sum(l)\n",
        "print('test positive {0} total {1}'.format(pos, ttl))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train positive 1890.0 total 9897\n",
            "test positive 329.0 total 1674\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_pYnU6jsgBy"
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, emb, input_dim, emb_dim, enc_hid_dim, dec_hid_dim, dropout):\n",
        "        super().__init__()\n",
        "        \n",
        "        print('New bert embedding')\n",
        "        #bertmodel = BertModel.from_pretrained('bert-base-uncased')\n",
        "        #bertmodel.resize_token_embeddings(input_dim)\n",
        "        #self.embedding = bertmodel.embeddings\n",
        "        self.embedding = emb\n",
        "        \n",
        "        self.rnn = nn.GRU(emb_dim, enc_hid_dim, bidirectional = True)\n",
        "        \n",
        "        self.fc = nn.Linear(enc_hid_dim * 2, dec_hid_dim)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, src):\n",
        "        \n",
        "        #src = [src len, batch size]\n",
        "        \n",
        "        embedded = self.dropout(self.embedding(src))\n",
        "        \n",
        "        #embedded = [src len, batch size, emb dim]\n",
        "        \n",
        "        outputs, hidden = self.rnn(embedded)\n",
        "                \n",
        "        #outputs = [src len, batch size, hid dim * num directions]\n",
        "        #hidden = [n layers * num directions, batch size, hid dim]\n",
        "        \n",
        "        #hidden is stacked [forward_1, backward_1, forward_2, backward_2, ...]\n",
        "        #outputs are always from the last layer\n",
        "        \n",
        "        #hidden [-2, :, : ] is the last of the forwards RNN \n",
        "        #hidden [-1, :, : ] is the last of the backwards RNN\n",
        "        \n",
        "        #initial decoder hidden is final hidden state of the forwards and backwards \n",
        "        #  encoder RNNs fed through a linear layer\n",
        "        hidden = torch.tanh(self.fc(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1)))\n",
        "        \n",
        "        #outputs = [src len, batch size, enc hid dim * 2]\n",
        "        #hidden = [batch size, dec hid dim]\n",
        "        \n",
        "        return outputs, hidden\n",
        "\n",
        "class Attention(nn.Module):\n",
        "    def __init__(self, enc_hid_dim, dec_hid_dim):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.attn = nn.Linear((enc_hid_dim * 2) + dec_hid_dim, dec_hid_dim)\n",
        "        self.v = nn.Linear(dec_hid_dim, 1, bias = False)\n",
        "        \n",
        "    def forward(self, hidden, encoder_outputs):\n",
        "        \n",
        "        #hidden = [batch size, dec hid dim]\n",
        "        #encoder_outputs = [src len, batch size, enc hid dim * 2]\n",
        "        \n",
        "        batch_size = encoder_outputs.shape[1]\n",
        "        src_len = encoder_outputs.shape[0]\n",
        "        \n",
        "        #repeat decoder hidden state src_len times\n",
        "        hidden = hidden.unsqueeze(1).repeat(1, src_len, 1)\n",
        "        \n",
        "        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
        "        \n",
        "        #hidden = [batch size, src len, dec hid dim]\n",
        "        #encoder_outputs = [batch size, src len, enc hid dim * 2]\n",
        "        \n",
        "        energy = torch.tanh(self.attn(torch.cat((hidden, encoder_outputs), dim = 2))) \n",
        "        \n",
        "        #energy = [batch size, src len, dec hid dim]\n",
        "\n",
        "        attention = self.v(energy).squeeze(2)\n",
        "        \n",
        "        #attention= [batch size, src len]\n",
        "        \n",
        "        return F.softmax(attention, dim=1)\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, emb, emb_dim, enc_hid_dim, dec_hid_dim, dropout, attention):\n",
        "        super().__init__()\n",
        "\n",
        "        self.attention = attention\n",
        "        \n",
        "        self.embedding = emb\n",
        "        \n",
        "        self.rnn = nn.GRU((enc_hid_dim * 2) + emb_dim, dec_hid_dim)\n",
        "        self.fc_out = nn.Linear((enc_hid_dim * 2) + dec_hid_dim + emb_dim, 1)\n",
        "        #self.fc_out = nn.Linear((enc_hid_dim * 2) + dec_hid_dim + emb_dim, 1)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, input, hidden, encoder_outputs):\n",
        "             \n",
        "        #input = [batch size]\n",
        "        #hidden = [batch size, dec hid dim]\n",
        "        #encoder_outputs = [src len, batch size, enc hid dim * 2]\n",
        "        \n",
        "        #input = input.unsqueeze(0)\n",
        "        \n",
        "        #input = [1, batch size]\n",
        "        \n",
        "        embedded = self.dropout(self.embedding(input))\n",
        "        \n",
        "        #embedded = [1, batch size, emb dim]\n",
        "        \n",
        "        a = self.attention(hidden, encoder_outputs)\n",
        "                \n",
        "        #a = [batch size, src len]\n",
        "        \n",
        "        a = a.unsqueeze(1)\n",
        "        \n",
        "        #a = [batch size, 1, src len]\n",
        "        \n",
        "        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
        "        \n",
        "        #encoder_outputs = [batch size, src len, enc hid dim * 2]\n",
        "        \n",
        "        weighted = torch.bmm(a, encoder_outputs)\n",
        "        \n",
        "        #weighted = [batch size, 1, enc hid dim * 2]\n",
        "        \n",
        "        weighted = weighted.permute(1, 0, 2)\n",
        "        \n",
        "        #weighted = [1, batch size, enc hid dim * 2]\n",
        "\n",
        "        #print(embedded.size())\n",
        "        #print(weighted.size())\n",
        "        \n",
        "        rnn_input = torch.cat((embedded, weighted), dim = 2)\n",
        "  \n",
        "        #rnn_input = [1, batch size, (enc hid dim * 2) + emb dim]\n",
        "            \n",
        "        output, hidden = self.rnn(rnn_input, hidden.unsqueeze(0))\n",
        "        \n",
        "        #output = [seq len, batch size, dec hid dim * n directions]\n",
        "        #hidden = [n layers * n directions, batch size, dec hid dim]\n",
        "        \n",
        "        #seq len, n layers and n directions will always be 1 in this decoder, therefore:\n",
        "        #output = [1, batch size, dec hid dim]\n",
        "        #hidden = [1, batch size, dec hid dim]\n",
        "        #this also means that output == hidden\n",
        "        assert (output == hidden).all()\n",
        "        \n",
        "        embedded = embedded.squeeze(0)\n",
        "        output = output.squeeze(0)\n",
        "        weighted = weighted.squeeze(0)\n",
        "        \n",
        "        #prediction = self.fc_out(torch.cat((output, weighted, embedded), dim = 1))\n",
        "        \n",
        "        prediction = self.fc_out(torch.cat((output, weighted, embedded), dim = 1))\n",
        "\n",
        "        #prediction = [batch size, output dim]\n",
        "        \n",
        "        return prediction, hidden.squeeze(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M7V4n2PquDGa"
      },
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder, device):\n",
        "          super().__init__()\n",
        "        \n",
        "          self.encoder = encoder\n",
        "          self.decoder = decoder\n",
        "          self.device = device\n",
        "          self.output_layer = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, src, trg):\n",
        "        \n",
        "        #src = [src len, batch size]\n",
        "        #trg = [trg len, batch size]\n",
        "        #teacher_forcing_ratio is probability to use teacher forcing\n",
        "        #e.g. if teacher_forcing_ratio is 0.75 we use teacher forcing 75% of the time\n",
        "        \n",
        "        batch_size = src.shape[1]\n",
        "        trg_len = trg.shape[0]\n",
        "        \n",
        "        #encoder_outputs is all hidden states of the input sequence, back and forwards\n",
        "        #hidden is the final forward and backward hidden states, passed through a linear layer\n",
        "        encoder_outputs, hidden = self.encoder(src)\n",
        "                \n",
        "        #first input to the decoder is the <sos> tokens\n",
        "        input = trg\n",
        "        #input =  torch.tensor([101]*BATCH_SIZE, device=device)\n",
        "          \n",
        "        #insert input token embedding, previous hidden state and all encoder hidden states\n",
        "        #receive output tensor (predictions) and new hidden state\n",
        "        output, hidden = self.decoder(input, hidden, encoder_outputs)\n",
        "        output = output.squeeze(1)\n",
        "        output = self.output_layer(output)\n",
        "          \n",
        "        return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cf8yLVQQvZl6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 149,
          "referenced_widgets": [
            "0e9ccd7df1c346f18c08d693c020201a",
            "1dd4bd60c2a14a48a8874fd6e1ff0198",
            "afa77d82ab9c4470ac6cb91ff450ae13",
            "19f87b9c354e48bfa9c1aa1821515401",
            "39701143bf1e436f92ccd57b8efac354",
            "d707fd4a3b414c30a629b6cdc0285765",
            "9a8c58ebba4947ccb7ab53920bcde607",
            "1359b51272df477995c20c8724810861",
            "0254095923c647d8986487d78b625d1f",
            "444dbba966d14c95977dc9980181dddb",
            "f4a603b606514cbcaa4af43f08e02682",
            "e4021fcf00ce49148b663644b96b955a",
            "248a52af67a14c01b1900202fc1815a4",
            "708f47eda91246d9ae51b75959256a8c",
            "7116a63b67714e3dbac50646fd72a4ee",
            "2df467bc3fba41b98baa5a5a2e48ac23"
          ]
        },
        "outputId": "d62d75dd-676c-47ac-fd21-00dd1874bd57"
      },
      "source": [
        "INPUT_DIM = len(tokenizer)\n",
        "ENC_EMB_DIM = 768 \n",
        "DEC_EMB_DIM = 768 \n",
        "ENC_HID_DIM = 256\n",
        "DEC_HID_DIM = 256\n",
        "ENC_DROPOUT = 0.5\n",
        "DEC_DROPOUT = 0.5\n",
        "\n",
        "print(INPUT_DIM)\n",
        "\n",
        "bertmodel = BertModel.from_pretrained('bert-base-uncased')\n",
        "emb = bertmodel.embeddings\n",
        "#emb = nn.Embedding(INPUT_DIM, ENC_EMB_DIM)\n",
        "attn = Attention(ENC_HID_DIM, DEC_HID_DIM)\n",
        "enc = Encoder(emb, INPUT_DIM, ENC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, ENC_DROPOUT)\n",
        "dec = Decoder(emb, DEC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, DEC_DROPOUT, attn)\n",
        "model = Seq2Seq(enc, dec, device).to(device)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "30522\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0e9ccd7df1c346f18c08d693c020201a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_â€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0254095923c647d8986487d78b625d1f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descriâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "New bert embedding\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kVyvYDtsP0_v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8299a16d-c641-4740-92f5-6da21a2b230a"
      },
      "source": [
        "def init_weights(m):\n",
        "    for name, param in m.named_parameters():\n",
        "        if 'weight' in name:\n",
        "            nn.init.normal_(param.data, mean=0, std=0.01)\n",
        "        else:\n",
        "            nn.init.constant_(param.data, 0)\n",
        "            \n",
        "model.apply(init_weights)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Seq2Seq(\n",
              "  (encoder): Encoder(\n",
              "    (embedding): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (rnn): GRU(768, 256, bidirectional=True)\n",
              "    (fc): Linear(in_features=512, out_features=256, bias=True)\n",
              "    (dropout): Dropout(p=0.5, inplace=False)\n",
              "  )\n",
              "  (decoder): Decoder(\n",
              "    (attention): Attention(\n",
              "      (attn): Linear(in_features=768, out_features=256, bias=True)\n",
              "      (v): Linear(in_features=256, out_features=1, bias=False)\n",
              "    )\n",
              "    (embedding): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (rnn): GRU(1280, 256)\n",
              "    (fc_out): Linear(in_features=1536, out_features=1, bias=True)\n",
              "    (dropout): Dropout(p=0.5, inplace=False)\n",
              "  )\n",
              "  (output_layer): Sigmoid()\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2BaHui5tw5kl"
      },
      "source": [
        "optimizer = optim.Adam(model.parameters())\n",
        "criterion = nn.BCELoss()\n",
        "def train(model, iterator, optimizer, criterion, clip):\n",
        " \n",
        "    #model.load_state_dict(torch.load('tut3-model.pt'))\n",
        "    model.train()\n",
        "\n",
        "    epoch_loss = 0  \n",
        "    acc = 0\n",
        "    total = 0\n",
        "    right = 0\n",
        "    num_iter = len(train_x)\n",
        "    for i in range(num_iter):\n",
        "    #for i, batch in enumerate(iterator):\n",
        "        #print('{0}/{1}'.format(i,len(train_input), end='\\r'))\n",
        "        src = train_x[i]\n",
        "        trg = train_xt[i]\n",
        "        #src = torch.transpose(src, 1, 0)\n",
        "        #trg = torch.transpose(trg, 1, 0)\n",
        "        #src.transpose_(0,1)\n",
        "        #trg.transpose_(0,1)\n",
        "        \n",
        "        #src = batch.src\n",
        "        #trg = batch.trg\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        output = model(src, trg)\n",
        "         \n",
        "        \n",
        "        #trg = [trg len, batch size]\n",
        "        #output = [trg len, batch size, output dim]\n",
        "        \n",
        "        #output_dim = output.shape[-1]\n",
        "        \n",
        "        #output = output[1:].view(-1, output_dim)\n",
        "\n",
        "        #trg = trg[1:].view(-1)\n",
        "        #trg = trg[1:].reshape((MAX_LENGTH-1)*trg[1:].size(1))\n",
        "\n",
        "        #trg = [(trg len - 1) * batch size]\n",
        "        #output = [(trg len - 1) * batch size, output dim]\n",
        "        \n",
        "        loss = criterion(output, train_y[i])\n",
        "        #print(output)\n",
        "        #print(train_y[i])\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "        y_pred = np.array(output.cpu().detach())\n",
        "        y_pred = np.where(y_pred <= 0.5, 0, y_pred)\n",
        "        y_pred = np.where(y_pred > 0.5, 1, y_pred)\n",
        "        ybar = train_y[i].cpu().detach().numpy()\n",
        "        acc += sum(y_pred==ybar)\n",
        "        total += len(ybar)\n",
        "    \n",
        "   \n",
        "    \n",
        "    return epoch_loss / num_iter, acc*1.0 / total"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wjg2a2D614mV"
      },
      "source": [
        "def evaluate(model, iterator, criterion, PRINT=False):\n",
        "    \n",
        "    w = open('test_org.qu.new', 'w')\n",
        "    model.eval()\n",
        "    epoch_loss = 0\n",
        "    acc = 0\n",
        "    total = 0\n",
        "    wr = 0\n",
        "    pre = ''\n",
        "    ts = ''\n",
        "    with torch.no_grad():\n",
        "        num_iter = len(test_x)\n",
        "        for i in range(num_iter):\n",
        "        #for i, batch in enumerate(iterator):\n",
        "            src = test_x[i]\n",
        "            trg = test_xt[i]\n",
        "            #src = torch.transpose(src, 1, 0)\n",
        "            #trg = torch.transpose(trg, 1, 0)\n",
        "            \n",
        "            output = model(src, trg) #turn off teacher forcing\n",
        "\n",
        "            #trg = [trg len, batch size]\n",
        "            #output = [trg len, batch size, output dim]\n",
        "\n",
        "            #output_dim = output.shape[-1]\n",
        "            \n",
        "            #output = output[1:].view(-1, output_dim)\n",
        "            #trg = trg[1:].view(-1)\n",
        "            #trg = trg[1:].reshape((MAX_LENGTH-1)*trg[1:].size(1))\n",
        "\n",
        "            #trg = [(trg len - 1) * batch size]\n",
        "            #output = [(trg len - 1) * batch size, output dim]\n",
        "\n",
        "            loss = criterion(output, test_y[i])\n",
        "            y_pred = np.array(output.cpu().detach())\n",
        "            y_pred = np.where(y_pred <= 0.5, 0.0, y_pred)\n",
        "            y_pred = np.where(y_pred > 0.5, 1.0, y_pred)\n",
        "            ybar = test_y[i].cpu().detach().numpy()\n",
        "            acc += sum(y_pred==ybar)\n",
        "            total += len(ybar)\n",
        "            epoch_loss += loss.item()\n",
        "            assert len(sent_x[i]) == len(y_pred) == len(ybar) == len(sent_t[i])\n",
        "            if PRINT:\n",
        "              for j in range(len(sent_x[i])):\n",
        "                #print('---------')\n",
        "                #print(sent_x[i][j])\n",
        "                #print(sent_t[i][j])\n",
        "                #print(y_pred[j])\n",
        "                #print(ybar[j])\n",
        "                if pre == '':\n",
        "                  pre = sent_x[i][j]\n",
        "                if pre != '' and pre != sent_x[i][j]:\n",
        "                  w.write(ts.strip() + '\\t' + pre + '\\n')\n",
        "                  pre = sent_x[i][j]\n",
        "                  ts = ''\n",
        "                t = sent_t[i][j]\n",
        "                t = t.replace('border','border_info')\n",
        "                t = t.replace('high','highlow')\n",
        "                t = 'table_' + t\n",
        "                if y_pred[j]==1.0:\n",
        "                  ts += (t + ' ') \n",
        "        w.write(ts.strip() + '\\t' + pre)    \n",
        "    w.close()  \n",
        "    print(f'\\t Val. Loss: {epoch_loss / num_iter:.3f} Test Acc: {acc*1.0 / total:.3f}')      \n",
        "        \n",
        "    return epoch_loss / num_iter, acc*1.0 / total"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nHtqmddb2H3v"
      },
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FVWIgEUD2Ju9"
      },
      "source": [
        "import time\n",
        "N_EPOCHS = 30\n",
        "CLIP = 5\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    start_time = time.time()  \n",
        "    train_loss, train_acc = train(model, None, optimizer, criterion, CLIP)\n",
        "    valid_loss, valid_acc = evaluate(model, None, criterion)\n",
        "    \n",
        "    end_time = time.time()\n",
        "    \n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'tut3-model.pt')\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} Train Acc: {train_acc:.3f}')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} Test Acc: {valid_acc:.3f}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iPVkA8hRROmF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "203b3327-1e6a-4dcc-92da-e0b0fca529b4"
      },
      "source": [
        "model.load_state_dict(torch.load('tut3-model-997.pt'))\n",
        "valid_loss, valid_acc = evaluate(model, None, criterion, PRINT=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\t Val. Loss: 0.021 Test Acc: 0.997\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dfQiszghlJfB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87619414-b842-446b-f61d-f1bc2329a87a"
      },
      "source": [
        "wr_arr = ['4', '24', '31', '34', '45', '57', '63', '83', '88', '91', '92', '105', '108', '109', '110', '118', '119', '120', '122', '123', '127', '129', '130', '137', '139', '140', '141', '142', '144', '157', '158', '159', '163', '166', '171', '175', '176', '177', '178', '179', '180', '181', '183', '186', '195', '196', '197', '200', '201', '202', '203', '205', '212', '213', '214', '216', '218', '220', '222', '223', '224', '226', '229', '230', '235', '236', '237', '238', '240', '241', '242', '243', '244', '245', '246', '247', '250', '251', '252', '253', '254', '255', '256', '257', '258', '259', '260', '261', '262', '264', '266', '267', '270', '271', '272', '274', '276']\n",
        "with open('test_org.qu', 'r') as f1, open('test_org.qu.new', 'r') as f2:\n",
        "  ls1 = f1.readlines()\n",
        "  ls2 = f2.readlines()\n",
        "\n",
        "cnt = 0\n",
        "i = 0\n",
        "for l1, l2 in zip(ls1, ls2):\n",
        "  if l1 != l2:\n",
        "    i += 1\n",
        "    if str(i) in wr_arr:\n",
        "      pass\n",
        "    else:\n",
        "      cnt += 1\n",
        "    print(l1.strip())\n",
        "    print(l2.strip())\n",
        "    print('====')\n",
        "\n",
        "print(1-len(wr_arr)/len(ls1)*1.0)\n",
        "print(cnt/len(ls1)*1.0)\n",
        "print(1-len(wr_arr)/len(ls1)*1.0-cnt/len(ls1)*1.0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "table_highlow table_state table_city\thow many states have a higher point than the highest point of the state with the largest capital city in the us\n",
            "table_highlow table_state\thow many states have a higher point than the highest point of the state with the largest capital city in the us\n",
            "====\n",
            "table_city\twhat is the smallest city in the us\n",
            "table_city table_state\twhat is the smallest city in the us\n",
            "====\n",
            "table_border_info table_city\twhat states border the state with the most cities\n",
            "table_border_info table_city table_state\twhat states border the state with the most cities\n",
            "====\n",
            "table_mountain\twhich is the highest peak not in alaska\n",
            "table_mountain table_border_info\twhich is the highest peak not in alaska\n",
            "====\n",
            "table_river table_border_info table_state\twhich rivers run through states that border the state with the capital austin\n",
            "table_river table_border_info\twhich rivers run through states that border the state with the capital austin\n",
            "====\n",
            "0.6523297491039426\n",
            "0.014336917562724014\n",
            "0.6379928315412186\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}